name: Update API Data

on:
  schedule:
    # Run daily at 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
    
    - name: Update GitHub Profile Data
      run: |
        python -c "
        import requests
        import json
        import datetime
        import time
        
        # GitHub API endpoint for user profile
        username = 'rahul-challa'
        api_url = f'https://api.github.com/users/{username}'
        
        def fetch_with_retry(url, max_retries=3, base_delay=2):
            '''Fetch data with retry logic for rate limiting'''
            for attempt in range(max_retries):
                try:
                    print(f'Attempt {attempt + 1}/{max_retries} for {url}')
                    response = requests.get(url, timeout=30)
                    
                    if response.status_code == 200:
                        return response.json(), response.status_code
                    elif response.status_code == 429:
                        # Rate limited - wait and retry
                        wait_time = base_delay * (2 ** attempt)
                        print(f'Rate limited (429). Waiting {wait_time} seconds before retry...')
                        if attempt < max_retries - 1:
                            time.sleep(wait_time)
                            continue
                        else:
                            print(f'Max retries reached for {url}')
                            return None, response.status_code
                    else:
                        print(f'Failed with status {response.status_code} from {url}')
                        return None, response.status_code
                except Exception as e:
                    print(f'Error with endpoint {url}: {str(e)}')
                    if attempt < max_retries - 1:
                        time.sleep(base_delay * (2 ** attempt))
                    continue
            return None, None
        
        try:
            # Add small delay before first request
            time.sleep(1)
            
            # Make request to GitHub API
            print(f'Fetching GitHub profile data for: {username}')
            user_data, status = fetch_with_retry(api_url)
            
            if user_data:
                print(f'User data keys: {list(user_data.keys())}')
                
                # Get repositories with delay
                time.sleep(1)
                print('Fetching repositories...')
                repos_data, repos_status = fetch_with_retry(f'{api_url}/repos?per_page=100&sort=updated')
                if repos_data:
                    user_data['repositories'] = repos_data
                    print(f'Found {len(user_data[\"repositories\"])} repositories')
                else:
                    print(f'Failed to fetch repositories: {repos_status}')
                
                # Get followers list with delay
                time.sleep(1)
                print('Fetching followers...')
                followers_data, followers_status = fetch_with_retry(f'{api_url}/followers?per_page=100')
                if followers_data:
                    user_data['followers_list'] = followers_data
                    print(f'Found {len(user_data[\"followers_list\"])} followers')
                else:
                    print(f'Failed to fetch followers: {followers_status}')
                
                # Create final data structure
                final_data = {
                    'lastUpdated': datetime.datetime.now().isoformat(),
                    'data': user_data
                }
                
                # Write to file
                with open('data/github-profile.json', 'w') as f:
                    json.dump(final_data, f, indent=2)
                
                print('GitHub profile data updated successfully')
            else:
                print(f'Failed to fetch GitHub data: {status}')
                print('Keeping existing GitHub data file - workflow will continue')
        except Exception as e:
            print(f'Error fetching GitHub data: {str(e)}')
            print('Keeping existing GitHub data file - workflow will continue')
        "
    
    - name: Update LeetCode Calendar Data
      continue-on-error: true
      run: |
        python -c "
        import requests
        import json
        import datetime
        import time
        
        # LeetCode API endpoints (prioritize alfa-leetcode-api as it's most reliable)
        username = 'Rahul_Challa'
        api_endpoints = [
            f'https://alfa-leetcode-api.onrender.com/{username}/calendar',
            f'https://leetcode-api.cyclic.app/{username}/calendar'
        ]
        
        def fetch_with_retry(url, max_retries=3, base_delay=5):
            '''Fetch data with retry logic for rate limiting'''
            for attempt in range(max_retries):
                try:
                    print(f'Attempt {attempt + 1}/{max_retries} for {url}')
                    response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                        return response.json(), response.status_code, response.headers
                    elif response.status_code == 429:
                        # Rate limited - wait and retry
                        wait_time = base_delay * (2 ** attempt)  # Exponential backoff
                        print(f'Rate limited (429). Waiting {wait_time} seconds before retry...')
                        if attempt < max_retries - 1:
                            time.sleep(wait_time)
                            continue
                        else:
                            print(f'Max retries reached for {url}')
                            return None, response.status_code, None
                    else:
                        print(f'Failed with status {response.status_code} from {url}')
                        return None, response.status_code, None
                except Exception as e:
                    print(f'Error with endpoint {url}: {str(e)}')
                    if attempt < max_retries - 1:
                        time.sleep(base_delay * (2 ** attempt))
                    continue
            return None, None, None
        
        data = None
        api_url = None
        response_status = None
        response_headers = None
        
        # Add delay before first request to avoid rate limits
        print('Waiting 2 seconds before making requests...')
        time.sleep(2)
        
        for endpoint in api_endpoints:
            result_data, status, headers = fetch_with_retry(endpoint)
            if result_data:
                data = result_data
                api_url = endpoint
                response_status = status
                response_headers = headers
                print(f'Successfully fetched calendar data from: {endpoint}')
                print(f'Received data keys: {list(data.keys()) if isinstance(data, dict) else \"Not a dict\"}')
                break
            else:
                print(f'Failed to fetch from {endpoint}')
                # Add delay between endpoint attempts
                if endpoint != api_endpoints[-1]:
                    print('Waiting 3 seconds before trying next endpoint...')
                    time.sleep(3)
        
        if data:
                # Create final data structure
                final_data = {
                    'lastUpdated': datetime.datetime.now().isoformat(),
                    'data': data,
                    'apiSource': api_url,
                'responseHeaders': dict(response_headers) if response_headers else None,
                'responseStatus': response_status,
                    'requestUrl': api_url
                }
                
                # Write to file
                with open('data/leetcode-calendar.json', 'w') as f:
                    json.dump(final_data, f, indent=2)
                
                print('LeetCode calendar data updated successfully')
            else:
            print('Failed to fetch LeetCode calendar data from all endpoints')
            print('Keeping existing calendar data file - workflow will continue')
        "
    
    - name: Update LeetCode Contest Data
      continue-on-error: true
      run: |
        python -c "
        import requests
        import json
        import datetime
        import time
        
        # LeetCode API endpoints (try multiple as fallback)
        username = 'Rahul_Challa'
        api_endpoints = [
            f'https://alfa-leetcode-api.onrender.com/{username}/contest',
            f'https://leetcode-api.cyclic.app/{username}/contest'
        ]
        
        def fetch_with_retry(url, max_retries=3, base_delay=5):
            '''Fetch data with retry logic for rate limiting'''
            for attempt in range(max_retries):
                try:
                    print(f'Attempt {attempt + 1}/{max_retries} for {url}')
                    response = requests.get(url, timeout=30)
                    
        if response.status_code == 200:
                        return response.json(), response.status_code, response.headers
                    elif response.status_code == 429:
                        # Rate limited - wait and retry
                        wait_time = base_delay * (2 ** attempt)  # Exponential backoff
                        print(f'Rate limited (429). Waiting {wait_time} seconds before retry...')
                        if attempt < max_retries - 1:
                            time.sleep(wait_time)
                            continue
                        else:
                            print(f'Max retries reached for {url}')
                            return None, response.status_code, None
                    else:
                        print(f'Failed with status {response.status_code} from {url}')
                        return None, response.status_code, None
                except Exception as e:
                    print(f'Error with endpoint {url}: {str(e)}')
                    if attempt < max_retries - 1:
                        time.sleep(base_delay * (2 ** attempt))
                    continue
            return None, None, None
        
        data = None
        api_url = None
        response_status = None
        response_headers = None
        
        # Add delay before first request to avoid rate limits
        print('Waiting 3 seconds before making requests...')
        time.sleep(3)
        
        for endpoint in api_endpoints:
            result_data, status, headers = fetch_with_retry(endpoint)
            if result_data:
                data = result_data
                api_url = endpoint
                response_status = status
                response_headers = headers
                print(f'Successfully fetched data from: {endpoint}')
                break
            else:
                print(f'Failed to fetch from {endpoint}')
                # Add delay between endpoint attempts
                if endpoint != api_endpoints[-1]:
                    print('Waiting 3 seconds before trying next endpoint...')
                    time.sleep(3)
        
        if data:
            # Create final data structure
            final_data = {
                'lastUpdated': datetime.datetime.now().isoformat(),
                'data': data,
                'apiSource': api_url,
                'responseHeaders': dict(response_headers) if response_headers else None,
                'responseStatus': response_status,
                'requestUrl': api_url
            }
            
            # Write to file
            with open('data/leetcode-contest.json', 'w') as f:
                json.dump(final_data, f, indent=2)
            
            print('LeetCode contest data updated successfully')
        else:
            print('Failed to fetch LeetCode contest data from all endpoints')
            print('Keeping existing contest data file - workflow will continue')
        "
    
    - name: Update LeetCode History Data
      continue-on-error: true
      run: |
        python -c "
        import requests
        import json
        import datetime
        import time
        
        # LeetCode API endpoints (try multiple as fallback)
        username = 'Rahul_Challa'
        api_endpoints = [
            f'https://alfa-leetcode-api.onrender.com/{username}/contest',
            f'https://leetcode-api.cyclic.app/{username}/contest'
        ]
        
        def fetch_with_retry(url, max_retries=3, base_delay=5):
            '''Fetch data with retry logic for rate limiting'''
            for attempt in range(max_retries):
                try:
                    print(f'Attempt {attempt + 1}/{max_retries} for {url}')
                    response = requests.get(url, timeout=30)
                    
        if response.status_code == 200:
                        return response.json(), response.status_code, response.headers
                    elif response.status_code == 429:
                        # Rate limited - wait and retry
                        wait_time = base_delay * (2 ** attempt)  # Exponential backoff
                        print(f'Rate limited (429). Waiting {wait_time} seconds before retry...')
                        if attempt < max_retries - 1:
                            time.sleep(wait_time)
                            continue
                        else:
                            print(f'Max retries reached for {url}')
                            return None, response.status_code, None
                    else:
                        print(f'Failed with status {response.status_code} from {url}')
                        return None, response.status_code, None
                except Exception as e:
                    print(f'Error with endpoint {url}: {str(e)}')
                    if attempt < max_retries - 1:
                        time.sleep(base_delay * (2 ** attempt))
                    continue
            return None, None, None
        
        contest_data = None
        api_url = None
        response_status = None
        response_headers = None
        
        # Add delay before first request to avoid rate limits
        print('Waiting 4 seconds before making requests...')
        time.sleep(4)
        
        for endpoint in api_endpoints:
            result_data, status, headers = fetch_with_retry(endpoint)
            if result_data:
                contest_data = result_data
                api_url = endpoint
                response_status = status
                response_headers = headers
                print(f'Successfully fetched history data from: {endpoint}')
                break
            else:
                print(f'Failed to fetch from {endpoint}')
                # Add delay between endpoint attempts
                if endpoint != api_endpoints[-1]:
                    print('Waiting 3 seconds before trying next endpoint...')
                    time.sleep(3)
        
        if contest_data:
            # Extract contest participation data which contains the history
            # Handle different API response structures
            if isinstance(contest_data, dict):
                if 'data' in contest_data and isinstance(contest_data['data'], dict):
                    contest_history = contest_data['data'].get('userContestRankingHistory', [])
                else:
                    contest_history = contest_data.get('contestParticipation', []) or contest_data.get('userContestRankingHistory', [])
            else:
                contest_history = []
            
            # Create history data structure similar to the original format
            history_data = {
                'count': len(contest_history),
                'contestHistory': contest_history
            }
            
            # Create final data structure
            final_data = {
                'lastUpdated': datetime.datetime.now().isoformat(),
                'data': history_data,
                'apiSource': api_url,
                'responseHeaders': dict(response_headers) if response_headers else None,
                'responseStatus': response_status,
                'requestUrl': api_url,
                'note': 'Data extracted from contest endpoint as history endpoint is not available'
            }
            
            # Write to file
            with open('data/leetcode-history.json', 'w') as f:
                json.dump(final_data, f, indent=2)
            
            print('LeetCode history data updated successfully from contest endpoint')
        else:
            print('Failed to fetch LeetCode history data from all endpoints')
            print('Keeping existing history data file')
        "
    
    - name: Update TexMex Package Data
      run: |
        python -c "
        import requests
        import json
        import datetime
        
        # NPM API endpoint for TexMex package
        package_name = 'texmex'
        api_url = f'https://registry.npmjs.org/{package_name}'
        
        try:
            # Make request to NPM API
            response = requests.get(api_url, timeout=30)
            if response.status_code == 200:
                data = response.json()
                
                # Extract latest version info
                latest_version = data.get('dist-tags', {}).get('latest')
                latest_data = data.get('versions', {}).get(latest_version, {})
                
                # Create final data structure
                final_data = {
                    'lastUpdated': datetime.datetime.now().isoformat(),
                    'data': {
                        'installs': None,  # NPM doesn't provide install count in registry API
                        'version': latest_version,
                        'rating': None,  # NPM doesn't provide ratings
                        'ratingCount': None,
                        'publisher': latest_data.get('publisher', {}).get('name'),
                        'displayName': latest_data.get('displayName'),
                        'description': latest_data.get('description'),
                        'categories': latest_data.get('categories', []),
                        'tags': latest_data.get('keywords', []),
                        'repository': latest_data.get('repository', {}).get('url'),
                        'homepage': latest_data.get('homepage'),
                        'bugs': latest_data.get('bugs', {}).get('url'),
                        'license': latest_data.get('license'),
                        'engines': latest_data.get('engines', {}),
                        'icon': latest_data.get('icon'),
                        'galleryBanner': latest_data.get('galleryBanner', {}),
                        'preview': latest_data.get('preview', False),
                        'public': True
                    },
                    'apiSource': api_url,
                    'responseHeaders': dict(response.headers),
                    'responseStatus': response.status_code
                }
                
                # Write to file
                with open('data/texmex-badges.json', 'w') as f:
                    json.dump(final_data, f, indent=2)
                
                print('TexMex package data updated successfully')
            else:
                print(f'Failed to fetch TexMex package data: {response.status_code}')
                # Create fallback data structure
                fallback_data = {
                    'lastUpdated': datetime.datetime.now().isoformat(),
                    'data': {
                        'installs': None,
                        'version': None,
                        'rating': None,
                        'ratingCount': None,
                        'publisher': None,
                        'displayName': None,
                        'description': None,
                        'categories': [],
                        'tags': [],
                        'repository': None,
                        'homepage': None,
                        'bugs': None,
                        'license': None,
                        'engines': {},
                        'icon': None,
                        'galleryBanner': {},
                        'preview': False,
                        'public': False
                    },
                    'apiSource': api_url,
                    'responseHeaders': None,
                    'responseStatus': response.status_code,
                    'error': f'API request failed with status {response.status_code}'
                }
                
                with open('data/texmex-badges.json', 'w') as f:
                    json.dump(fallback_data, f, indent=2)
                
                print('Created fallback TexMex data due to API failure')
        except Exception as e:
            print(f'Error fetching TexMex package data: {str(e)}')
            # Create error data structure
            error_data = {
                'lastUpdated': datetime.datetime.now().isoformat(),
                'data': {
                    'installs': None,
                    'version': None,
                    'rating': None,
                    'ratingCount': None,
                    'publisher': None,
                    'displayName': None,
                    'description': None,
                    'categories': [],
                    'tags': [],
                    'repository': None,
                    'homepage': None,
                    'bugs': None,
                    'license': None,
                    'engines': {},
                    'icon': None,
                    'galleryBanner': {},
                    'preview': False,
                    'public': False
                },
                'apiSource': api_url,
                'responseHeaders': None,
                'responseStatus': None,
                'error': str(e)
            }
            
            with open('data/texmex-badges.json', 'w') as f:
                json.dump(error_data, f, indent=2)
            
            print('Created error TexMex data due to exception')
        "
    
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Reset to match remote exactly and avoid any conflicts
        echo "Resetting to match remote main branch..."
        git fetch origin main
        git reset --hard origin/main
        
        # Check what files we have in data directory
        echo "Files in data directory:"
        ls -la data/
        
        # Check if any data files were actually updated
        echo "Checking for changes in data files..."
        git status
        
        # Now add and commit our changes
        git add data/
        
        # Check if there are any changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit - data files are up to date"
        else
          git commit -m "Update API data - $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          echo "Committed changes to data files"
        fi
        
        # Push should now work since we're exactly matching remote
        git push origin main
        echo "Successfully updated and pushed API data"
